<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/Cargo.toml">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Cargo.toml" />
              <option name="originalContent" value="[package]&#10;name = &quot;rust_ingester&quot;&#10;version = &quot;0.1.0&quot;&#10;edition = &quot;2021&quot;&#10;&#10;# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html&#10;&#10;[dependencies]&#10;dotenvy = &quot;0.15&quot;&#10;anyhow = &quot;1.0.100&quot;&#10;tokio = { version = &quot;1.37.0&quot;, features = [&quot;macros&quot;,&quot;rt-multi-thread&quot;, &quot;fs&quot;] }&#10;tokio-postgres = {version = &quot;0.7.15&quot;, features = [&quot;with-chrono-0_4&quot;, &quot;with-serde_json-1&quot;]}&#10;serde = { version = &quot;1.0&quot;, features = [&quot;derive&quot;] }&#10;serde_json = &quot;1.0&quot;&#10;pgvector = {version = &quot;0.3.1&quot;, features=[&quot;postgres&quot;]}&#10;ndarray = &quot;0.15&quot;&#10;rand = &quot;0.8&quot;&#10;llama_cpp = { version = &quot;0.3.2&quot;, default-features = false, features = [&quot;metal&quot;] }&#10;reqwest = { version = &quot;0.11&quot;, features = [&quot;json&quot;] }&#10;&#10;# Web service dependencies&#10;axum = &quot;0.7&quot;&#10;tower = &quot;0.4&quot;&#10;tower-http = { version = &quot;0.5&quot;, features = [&quot;cors&quot;, &quot;trace&quot;] }&#10;tracing = &quot;0.1&quot;&#10;tracing-subscriber = { version = &quot;0.3&quot;, features = [&quot;env-filter&quot;] }&#10;uuid = { version = &quot;1.0&quot;, features = [&quot;serde&quot;, &quot;v4&quot;] }&#10;&#10;[[bin]]&#10;name = &quot;service&quot;&#10;path = &quot;src/bin/service.rs&quot;&#10;&#10;[[bin]]&#10;name = &quot;ingest_cli&quot;&#10;path = &quot;src/bin/ingest_cli.rs&quot;" />
              <option name="updatedContent" value="[package]&#10;name = &quot;rust_ingester&quot;&#10;version = &quot;0.1.0&quot;&#10;edition = &quot;2021&quot;&#10;&#10;# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html&#10;&#10;[dependencies]&#10;dotenvy = &quot;0.15&quot;&#10;anyhow = &quot;1.0.100&quot;&#10;tokio = { version = &quot;1.37.0&quot;, features = [&quot;macros&quot;,&quot;rt-multi-thread&quot;, &quot;fs&quot;] }&#10;tokio-postgres = {version = &quot;0.7.15&quot;, features = [&quot;with-chrono-0_4&quot;, &quot;with-serde_json-1&quot;, &quot;with-uuid-1&quot;]}&#10;serde = { version = &quot;1.0&quot;, features = [&quot;derive&quot;] }&#10;serde_json = &quot;1.0&quot;&#10;pgvector = {version = &quot;0.3.1&quot;, features=[&quot;postgres&quot;]}&#10;ndarray = &quot;0.15&quot;&#10;rand = &quot;0.8&quot;&#10;chrono = &quot;0.4&quot;&#10;llama_cpp = { version = &quot;0.3.2&quot;, default-features = false, features = [&quot;metal&quot;] }&#10;reqwest = { version = &quot;0.11&quot;, features = [&quot;json&quot;] }&#10;&#10;# Web service dependencies&#10;axum = &quot;0.7&quot;&#10;tower = &quot;0.4&quot;&#10;tower-http = { version = &quot;0.5&quot;, features = [&quot;cors&quot;, &quot;trace&quot;] }&#10;tracing = &quot;0.1&quot;&#10;tracing-subscriber = { version = &quot;0.3&quot;, features = [&quot;env-filter&quot;] }&#10;uuid = { version = &quot;1.0&quot;, features = [&quot;serde&quot;, &quot;v4&quot;] }&#10;&#10;[[bin]]&#10;name = &quot;service&quot;&#10;path = &quot;src/bin/service.rs&quot;&#10;&#10;[[bin]]&#10;name = &quot;ingest_cli&quot;&#10;path = &quot;src/bin/ingest_cli.rs&quot;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/migrations/001_messages_and_embeddings.sql">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/migrations/001_messages_and_embeddings.sql" />
              <option name="updatedContent" value="-- Enable pgvector extension for efficient vector operations&#10;CREATE EXTENSION IF NOT EXISTS vector;&#10;CREATE EXTENSION IF NOT EXISTS &quot;uuid-ossp&quot;;&#10;&#10;-- Conversations table to store conversation metadata&#10;CREATE TABLE IF NOT EXISTS conversations (&#10;    conversation_id UUID PRIMARY KEY,&#10;    created_at TIMESTAMP DEFAULT NOW(),&#10;    updated_at TIMESTAMP DEFAULT NOW(),&#10;    metadata JSONB DEFAULT '{}'::jsonb&#10;);&#10;&#10;-- Messages table to store full message content&#10;CREATE TABLE IF NOT EXISTS messages (&#10;    message_id UUID PRIMARY KEY,&#10;    conversation_id UUID NOT NULL REFERENCES conversations(conversation_id) ON DELETE CASCADE,&#10;    content TEXT NOT NULL,&#10;    created_at TIMESTAMP DEFAULT NOW(),&#10;    metadata JSONB DEFAULT '{}'::jsonb&#10;);&#10;&#10;-- Message embeddings with pgvector (768-dim Nomic embeddings)&#10;CREATE TABLE IF NOT EXISTS message_embeddings (&#10;    message_id UUID PRIMARY KEY REFERENCES messages(message_id) ON DELETE CASCADE,&#10;    embedding vector(768) NOT NULL,&#10;    embedding_model VARCHAR(100) DEFAULT 'nomic-embed-text-v1.5',&#10;    created_at TIMESTAMP DEFAULT NOW()&#10;);&#10;&#10;-- Knowledge graph nodes (from enhanced pipeline)&#10;CREATE TABLE IF NOT EXISTS kg_nodes (&#10;    node_id VARCHAR(255),&#10;    conversation_id UUID REFERENCES conversations(conversation_id) ON DELETE CASCADE,&#10;    node_type VARCHAR(100),&#10;    created_at TIMESTAMP DEFAULT NOW(),&#10;    PRIMARY KEY (node_id, conversation_id)&#10;);&#10;&#10;-- Knowledge graph edges with evidence message IDs&#10;CREATE TABLE IF NOT EXISTS kg_edges (&#10;    edge_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),&#10;    conversation_id UUID REFERENCES conversations(conversation_id) ON DELETE CASCADE,&#10;    source_node VARCHAR(255) NOT NULL,&#10;    target_node VARCHAR(255) NOT NULL,&#10;    relation VARCHAR(255) NOT NULL,&#10;    evidence_message_ids UUID[] NOT NULL,&#10;    created_at TIMESTAMP DEFAULT NOW()&#10;);&#10;&#10;-- Indexes for performance&#10;CREATE INDEX IF NOT EXISTS idx_messages_conversation ON messages(conversation_id);&#10;CREATE INDEX IF NOT EXISTS idx_message_embeddings_ivfflat ON message_embeddings &#10;    USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);&#10;CREATE INDEX IF NOT EXISTS idx_kg_edges_conversation ON kg_edges(conversation_id);&#10;CREATE INDEX IF NOT EXISTS idx_kg_edges_evidence ON kg_edges USING GIN(evidence_message_ids);&#10;CREATE INDEX IF NOT EXISTS idx_kg_nodes_conversation ON kg_nodes(conversation_id);&#10;CREATE INDEX IF NOT EXISTS idx_kg_nodes_type ON kg_nodes(node_type);&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/api/context_handlers.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/api/context_handlers.rs" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="use axum::{http::StatusCode, Json};&#10;use serde::{Deserialize, Serialize};&#10;use std::collections::HashSet;&#10;use uuid::Uuid;&#10;use crate::db::{models::*, message_ops::*, kg_ops::*, connect::get_client};&#10;&#10;// ============================================================================&#10;// Request/Response Types&#10;// ============================================================================&#10;&#10;#[derive(Debug, Deserialize)]&#10;pub struct ContextQueryRequest {&#10;    pub query: String,&#10;    pub top_k: Option&lt;usize&gt;,&#10;    pub max_tokens: Option&lt;usize&gt;, // e.g., 4000 for context window&#10;    pub include_kg_edges: Option&lt;bool&gt;,&#10;}&#10;&#10;#[derive(Debug, Serialize)]&#10;pub struct ContextQueryResponse {&#10;    pub formatted_context: FormattedLLMContext,&#10;    pub knowledge_graph_edges: Vec&lt;KGEdgeWithContext&gt;,&#10;    pub query_duration_ms: u128,&#10;    pub total_evidence_messages: usize,&#10;}&#10;&#10;// ============================================================================&#10;// LLM Context Query Handler&#10;// ============================================================================&#10;&#10;/// Query for LLM context based on a natural language query&#10;/// This retrieves relevant knowledge graph edges and their associated message content&#10;pub async fn query_llm_context(&#10;    Json(payload): Json&lt;ContextQueryRequest&gt;,&#10;) -&gt; Result&lt;Json&lt;ContextQueryResponse&gt;, StatusCode&gt; {&#10;    let start = std::time::Instant::now();&#10;&#10;    let top_k = payload.top_k.unwrap_or(10);&#10;    let max_tokens = payload.max_tokens.unwrap_or(4000);&#10;    let include_kg_edges = payload.include_kg_edges.unwrap_or(true);&#10;&#10;    println!(&quot;Querying LLM context for: '{}' (top_k={}, max_tokens={})&quot;, &#10;        payload.query, top_k, max_tokens);&#10;&#10;    let client = match get_client().await {&#10;        Ok(c) =&gt; c,&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Failed to connect to database: {}&quot;, e);&#10;            return Err(StatusCode::INTERNAL_SERVER_ERROR);&#10;        }&#10;    };&#10;&#10;    // Step 1: Extract keywords from query (simple split for now)&#10;    let keywords: Vec&lt;String&gt; = payload.query&#10;        .split_whitespace()&#10;        .filter(|s| s.len() &gt; 2) // Filter out very short words&#10;        .map(|s| s.to_lowercase())&#10;        .collect();&#10;&#10;    println!(&quot;Extracted keywords: {:?}&quot;, keywords);&#10;&#10;    // Step 2: Query knowledge graph for relevant edges&#10;    let kg_edges = match get_edges_by_query(&amp;client, &amp;keywords, top_k as i64).await {&#10;        Ok(edges) =&gt; edges,&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Error querying knowledge graph: {}&quot;, e);&#10;            return Err(StatusCode::INTERNAL_SERVER_ERROR);&#10;        }&#10;    };&#10;&#10;    println!(&quot;Found {} relevant KG edges&quot;, kg_edges.len());&#10;&#10;    // Step 3: Extract and deduplicate evidence message IDs&#10;    let mut message_ids: Vec&lt;Uuid&gt; = kg_edges&#10;        .iter()&#10;        .flat_map(|edge| edge.evidence_message_ids.clone())&#10;        .collect();&#10;    &#10;    // Remove duplicates while preserving order&#10;    let mut seen = HashSet::new();&#10;    message_ids.retain(|id| seen.insert(*id));&#10;&#10;    let total_evidence_messages = message_ids.len();&#10;    println!(&quot;Found {} unique evidence message IDs&quot;, total_evidence_messages);&#10;&#10;    // Step 4: Retrieve full messages ordered by relevance (order in KG results)&#10;    let messages = match get_messages_by_ids_ordered(&amp;client, &amp;message_ids).await {&#10;        Ok(msgs) =&gt; msgs,&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Error retrieving messages: {}&quot;, e);&#10;            return Err(StatusCode::INTERNAL_SERVER_ERROR);&#10;        }&#10;    };&#10;&#10;    println!(&quot;Retrieved {} full messages&quot;, messages.len());&#10;&#10;    // Step 5: Format for LLM context with token estimation&#10;    let formatted = format_messages_for_llm(messages, max_tokens);&#10;&#10;    println!(&quot;Formatted {} messages for LLM (estimated {} tokens, {:.1}% of context window)&quot;,&#10;        formatted.messages.len(), &#10;        formatted.total_tokens_estimate,&#10;        formatted.context_window_used);&#10;&#10;    let response = ContextQueryResponse {&#10;        formatted_context: formatted,&#10;        knowledge_graph_edges: if include_kg_edges { kg_edges } else { Vec::new() },&#10;        query_duration_ms: start.elapsed().as_millis(),&#10;        total_evidence_messages,&#10;    };&#10;&#10;    Ok(Json(response))&#10;}&#10;&#10;// ============================================================================&#10;// Helper Functions&#10;// ============================================================================&#10;&#10;/// Format messages for LLM consumption with token budget management&#10;fn format_messages_for_llm(&#10;    messages: Vec&lt;Message&gt;,&#10;    max_tokens: usize,&#10;) -&gt; FormattedLLMContext {&#10;    let mut llm_messages = Vec::new();&#10;    let mut total_tokens = 0;&#10;    let tokens_per_char = 0.25; // rough estimate: 1 token ≈ 4 chars&#10;&#10;    // Track unique conversations&#10;    let mut conversations = HashSet::new();&#10;&#10;    for (idx, msg) in messages.iter().enumerate() {&#10;        let estimated_tokens = (msg.content.len() as f32 * tokens_per_char) as usize;&#10;&#10;        // Stop if we exceed token budget&#10;        if total_tokens + estimated_tokens &gt; max_tokens {&#10;            println!(&quot;Reached token limit at message {} of {}&quot;, idx + 1, messages.len());&#10;            break;&#10;        }&#10;&#10;        conversations.insert(msg.conversation_id);&#10;&#10;        // Calculate relevance score (higher for earlier messages in result set)&#10;        let relevance_score = 1.0 - (idx as f32 / messages.len().max(1) as f32);&#10;&#10;        // Parse role from message content if possible&#10;        let (role, content) = parse_message_role(&amp;msg.content);&#10;&#10;        llm_messages.push(LLMContextMessage {&#10;            role,&#10;            content,&#10;            message_id: msg.message_id,&#10;            relevance_score,&#10;        });&#10;&#10;        total_tokens += estimated_tokens;&#10;    }&#10;&#10;    FormattedLLMContext {&#10;        messages: llm_messages,&#10;        total_tokens_estimate: total_tokens,&#10;        context_window_used: (total_tokens as f32 / max_tokens as f32) * 100.0,&#10;        unique_conversations: conversations.len(),&#10;    }&#10;}&#10;&#10;/// Parse message role from content (e.g., &quot;user: hello&quot; -&gt; (&quot;user&quot;, &quot;hello&quot;))&#10;fn parse_message_role(content: &amp;str) -&gt; (String, String) {&#10;    // Check if content starts with a role prefix like &quot;user:&quot; or &quot;assistant:&quot;&#10;    let parts: Vec&lt;&amp;str&gt; = content.splitn(2, ':').collect();&#10;    &#10;    if parts.len() == 2 {&#10;        let potential_role = parts[0].trim().to_lowercase();&#10;        if matches!(potential_role.as_str(), &quot;user&quot; | &quot;assistant&quot; | &quot;system&quot;) {&#10;            return (potential_role, parts[1].trim().to_string());&#10;        }&#10;    }&#10;    &#10;    // Default to &quot;user&quot; if no role prefix found&#10;    (&quot;user&quot;.to_string(), content.to_string())&#10;}&#10;&#10;// ============================================================================&#10;// Direct Message Query Handler&#10;// ============================================================================&#10;&#10;#[derive(Debug, Deserialize)]&#10;pub struct MessageQueryRequest {&#10;    pub message_ids: Vec&lt;Uuid&gt;,&#10;}&#10;&#10;#[derive(Debug, Serialize)]&#10;pub struct MessageQueryResponse {&#10;    pub messages: Vec&lt;Message&gt;,&#10;    pub total_found: usize,&#10;}&#10;&#10;/// Get full messages by their IDs&#10;pub async fn query_messages_by_ids(&#10;    Json(payload): Json&lt;MessageQueryRequest&gt;,&#10;) -&gt; Result&lt;Json&lt;MessageQueryResponse&gt;, StatusCode&gt; {&#10;    println!(&quot;Querying {} message IDs&quot;, payload.message_ids.len());&#10;&#10;    let client = match get_client().await {&#10;        Ok(c) =&gt; c,&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Failed to connect to database: {}&quot;, e);&#10;            return Err(StatusCode::INTERNAL_SERVER_ERROR);&#10;        }&#10;    };&#10;&#10;    match get_messages_by_ids_ordered(&amp;client, &amp;payload.message_ids).await {&#10;        Ok(messages) =&gt; {&#10;            let total_found = messages.len();&#10;            println!(&quot;Found {} messages&quot;, total_found);&#10;            &#10;            Ok(Json(MessageQueryResponse {&#10;                messages,&#10;                total_found,&#10;            }))&#10;        }&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Error querying messages: {}&quot;, e);&#10;            Err(StatusCode::INTERNAL_SERVER_ERROR)&#10;        }&#10;    }&#10;}&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/api/ingest_handlers.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/api/ingest_handlers.rs" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="use axum::{http::StatusCode, Json};&#10;use serde::Deserialize;&#10;use crate::db::{models::*, message_ops::*, kg_ops::*, connect::get_client};&#10;&#10;// ============================================================================&#10;// Request/Response Types&#10;// ============================================================================&#10;&#10;#[derive(Debug, Deserialize)]&#10;pub struct BatchMessageIngestRequest {&#10;    #[serde(flatten)]&#10;    pub turns: Vec&lt;TurnEmbedding&gt;,&#10;}&#10;&#10;// ============================================================================&#10;// Message Ingestion Handler&#10;// ============================================================================&#10;&#10;/// Ingest messages with their full embeddings from turn_embeddings.json&#10;pub async fn ingest_turn_embeddings(&#10;    Json(payload): Json&lt;Vec&lt;TurnEmbedding&gt;&gt;,&#10;) -&gt; Result&lt;Json&lt;IngestResponse&gt;, StatusCode&gt; {&#10;    let start = std::time::Instant::now();&#10;    let total_processed = payload.len();&#10;&#10;    println!(&quot;Starting ingestion of {} turn embeddings&quot;, total_processed);&#10;&#10;    let client = match get_client().await {&#10;        Ok(c) =&gt; c,&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Failed to connect to database: {}&quot;, e);&#10;            return Err(StatusCode::INTERNAL_SERVER_ERROR);&#10;        }&#10;    };&#10;&#10;    match batch_insert_messages(&amp;client, &amp;payload).await {&#10;        Ok((count, errors)) =&gt; {&#10;            println!(&quot;Successfully ingested {} messages&quot;, count);&#10;            &#10;            Ok(Json(IngestResponse {&#10;                success: errors.is_empty(),&#10;                total_processed,&#10;                total_inserted: count,&#10;                duration_ms: start.elapsed().as_millis(),&#10;                errors,&#10;            }))&#10;        }&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Error during batch insert: {}&quot;, e);&#10;            Err(StatusCode::INTERNAL_SERVER_ERROR)&#10;        }&#10;    }&#10;}&#10;&#10;// ============================================================================&#10;// Knowledge Graph Ingestion Handler&#10;// ============================================================================&#10;&#10;/// Ingest knowledge graph data from enhanced_pipeline_full_results.json&#10;pub async fn ingest_knowledge_graph(&#10;    Json(payload): Json&lt;ConversationKnowledgeGraph&gt;,&#10;) -&gt; Result&lt;Json&lt;IngestResponse&gt;, StatusCode&gt; {&#10;    let start = std::time::Instant::now();&#10;    &#10;    let total_processed: usize = payload.conversations.values()&#10;        .map(|kg| kg.nodes.len() + kg.edges.len())&#10;        .sum();&#10;&#10;    println!(&quot;Starting ingestion of knowledge graph with {} conversations&quot;, &#10;        payload.conversations.len());&#10;&#10;    let client = match get_client().await {&#10;        Ok(c) =&gt; c,&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Failed to connect to database: {}&quot;, e);&#10;            return Err(StatusCode::INTERNAL_SERVER_ERROR);&#10;        }&#10;    };&#10;&#10;    match batch_insert_knowledge_graph(&amp;client, payload).await {&#10;        Ok((nodes, edges, errors)) =&gt; {&#10;            println!(&quot;Successfully ingested {} nodes and {} edges&quot;, nodes, edges);&#10;            &#10;            Ok(Json(IngestResponse {&#10;                success: errors.is_empty(),&#10;                total_processed,&#10;                total_inserted: nodes + edges,&#10;                duration_ms: start.elapsed().as_millis(),&#10;                errors,&#10;            }))&#10;        }&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Error during knowledge graph insert: {}&quot;, e);&#10;            Err(StatusCode::INTERNAL_SERVER_ERROR)&#10;        }&#10;    }&#10;}&#10;&#10;// ============================================================================&#10;// Statistics Handler&#10;// ============================================================================&#10;&#10;/// Get statistics about ingested data&#10;pub async fn get_statistics() -&gt; Result&lt;Json&lt;serde_json::Value&gt;, StatusCode&gt; {&#10;    let client = match get_client().await {&#10;        Ok(c) =&gt; c,&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Failed to connect to database: {}&quot;, e);&#10;            return Err(StatusCode::INTERNAL_SERVER_ERROR);&#10;        }&#10;    };&#10;&#10;    match get_kg_statistics(&amp;client).await {&#10;        Ok(stats) =&gt; Ok(Json(stats)),&#10;        Err(e) =&gt; {&#10;            eprintln!(&quot;Error fetching statistics: {}&quot;, e);&#10;            Err(StatusCode::INTERNAL_SERVER_ERROR)&#10;        }&#10;    }&#10;}&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/api/mod.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/api/mod.rs" />
              <option name="originalContent" value="pub mod handlers;&#10;pub mod models;&#10;pub mod routes;&#10;" />
              <option name="updatedContent" value="pub mod handlers;&#10;pub mod models;&#10;pub mod routes;&#10;pub mod ingest_handlers;&#10;pub mod context_handlers;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/api/routes.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/api/routes.rs" />
              <option name="originalContent" value="use axum::{&#10;    routing::{get, post},&#10;    Router,&#10;};&#10;use tower_http::cors::CorsLayer;&#10;use tower_http::trace::TraceLayer;&#10;&#10;use super::handlers;&#10;&#10;pub fn create_router() -&gt; Router {&#10;    Router::new()&#10;        // Health check&#10;        .route(&quot;/status&quot;, get(handlers::health_check))&#10;        &#10;        // Ingestion endpoints&#10;        .route(&quot;/ingest/session&quot;, post(handlers::ingest_session))&#10;        .route(&quot;/ingest/batch&quot;, post(handlers::ingest_batch))&#10;        &#10;        // Query endpoints&#10;        .route(&quot;/query/similar&quot;, post(handlers::query_similar))&#10;        .route(&quot;/query/session/:session_id&quot;, get(handlers::get_session))&#10;        &#10;        // Graph query endpoint&#10;        .route(&quot;/graph/cypher&quot;, post(handlers::execute_cypher))&#10;        &#10;        // Middleware&#10;        .layer(CorsLayer::permissive())&#10;        .layer(TraceLayer::new_for_http())&#10;}&#10;" />
              <option name="updatedContent" value="use axum::{&#10;    routing::{get, post},&#10;    Router,&#10;};&#10;use tower_http::cors::CorsLayer;&#10;use tower_http::trace::TraceLayer;&#10;&#10;use super::handlers;&#10;use super::ingest_handlers;&#10;use super::context_handlers;&#10;&#10;pub fn create_router() -&gt; Router {&#10;    Router::new()&#10;        // Health check&#10;        .route(&quot;/status&quot;, get(handlers::health_check))&#10;        &#10;        // Ingestion endpoints&#10;        .route(&quot;/ingest/session&quot;, post(handlers::ingest_session))&#10;        .route(&quot;/ingest/batch&quot;, post(handlers::ingest_batch))&#10;        &#10;        // New: Message and Knowledge Graph ingestion&#10;        .route(&quot;/ingest/messages&quot;, post(ingest_handlers::ingest_turn_embeddings))&#10;        .route(&quot;/ingest/knowledge-graph&quot;, post(ingest_handlers::ingest_knowledge_graph))&#10;        .route(&quot;/ingest/statistics&quot;, get(ingest_handlers::get_statistics))&#10;        &#10;        // Query endpoints&#10;        .route(&quot;/query/similar&quot;, post(handlers::query_similar))&#10;        .route(&quot;/query/session/:session_id&quot;, get(handlers::get_session))&#10;        &#10;        // New: LLM Context query endpoints&#10;        .route(&quot;/query/llm-context&quot;, post(context_handlers::query_llm_context))&#10;        .route(&quot;/query/messages&quot;, post(context_handlers::query_messages_by_ids))&#10;        &#10;        // Graph query endpoint&#10;        .route(&quot;/graph/cypher&quot;, post(handlers::execute_cypher))&#10;        &#10;        // Middleware&#10;        .layer(CorsLayer::permissive())&#10;        .layer(TraceLayer::new_for_http())&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/bin/service.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/bin/service.rs" />
              <option name="originalContent" value="use rust_ingester::api::routes;&#10;use std::net::SocketAddr;&#10;use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};&#10;&#10;#[tokio::main]&#10;async fn main() {&#10;    // Initialize tracing&#10;    tracing_subscriber::registry()&#10;        .with(&#10;            tracing_subscriber::EnvFilter::try_from_default_env()&#10;                .unwrap_or_else(|_| &quot;rust_ingester=debug,tower_http=debug,axum=trace&quot;.into()),&#10;        )&#10;        .with(tracing_subscriber::fmt::layer())&#10;        .init();&#10;&#10;    // Load environment variables&#10;    dotenvy::dotenv().ok();&#10;&#10;    // Get port from environment or use default&#10;    let port = std::env::var(&quot;SERVER_PORT&quot;)&#10;        .ok()&#10;        .and_then(|p| p.parse::&lt;u16&gt;().ok())&#10;        .unwrap_or(3000);&#10;&#10;    let addr = SocketAddr::from(([0, 0, 0, 0], port));&#10;&#10;    tracing::info!(&quot; RustIngester Service starting on {}&quot;, addr);&#10;    tracing::info!(&quot; Endpoints:&quot;);&#10;    tracing::info!(&quot;   GET  /status&quot;);&#10;    tracing::info!(&quot;   POST /ingest/session&quot;);&#10;    tracing::info!(&quot;   POST /ingest/batch&quot;);&#10;    tracing::info!(&quot;   POST /query/similar&quot;);&#10;    tracing::info!(&quot;   GET  /query/session/:session_id&quot;);&#10;    tracing::info!(&quot;   POST /graph/cypher&quot;);&#10;&#10;    // Create router&#10;    let app = routes::create_router();&#10;&#10;    // Run server&#10;    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();&#10;    tracing::info!(&quot;✅ Server listening on {}&quot;, addr);&#10;    &#10;    axum::serve(listener, app).await.unwrap();&#10;}&#10;" />
              <option name="updatedContent" value="use rust_ingester::api::routes;&#10;use std::net::SocketAddr;&#10;use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};&#10;&#10;#[tokio::main]&#10;async fn main() {&#10;    // Initialize tracing&#10;    tracing_subscriber::registry()&#10;        .with(&#10;            tracing_subscriber::EnvFilter::try_from_default_env()&#10;                .unwrap_or_else(|_| &quot;rust_ingester=debug,tower_http=debug,axum=trace&quot;.into()),&#10;        )&#10;        .with(tracing_subscriber::fmt::layer())&#10;        .init();&#10;&#10;    // Load environment variables&#10;    dotenvy::dotenv().ok();&#10;&#10;    // Get port from environment or use default&#10;    let port = std::env::var(&quot;SERVER_PORT&quot;)&#10;        .ok()&#10;        .and_then(|p| p.parse::&lt;u16&gt;().ok())&#10;        .unwrap_or(3000);&#10;&#10;    let addr = SocketAddr::from(([0, 0, 0, 0], port));&#10;&#10;    tracing::info!(&quot; RustIngester Service starting on {}&quot;, addr);&#10;    tracing::info!(&quot; Endpoints:&quot;);&#10;    tracing::info!(&quot;   GET  /status&quot;);&#10;    tracing::info!(&quot;   POST /ingest/session&quot;);&#10;    tracing::info!(&quot;   POST /ingest/batch&quot;);&#10;    tracing::info!(&quot;   POST /ingest/messages&quot;);&#10;    tracing::info!(&quot;   POST /ingest/knowledge-graph&quot;);&#10;    tracing::info!(&quot;   GET  /ingest/statistics&quot;);&#10;    tracing::info!(&quot;   POST /query/similar&quot;);&#10;    tracing::info!(&quot;   GET  /query/session/:session_id&quot;);&#10;    tracing::info!(&quot;   POST /query/llm-context&quot;);&#10;    tracing::info!(&quot;   POST /query/messages&quot;);&#10;    tracing::info!(&quot;   POST /graph/cypher&quot;);&#10;&#10;    // Create router&#10;    let app = routes::create_router();&#10;&#10;    // Run server&#10;    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();&#10;    tracing::info!(&quot;✅ Server listening on {}&quot;, addr);&#10;    &#10;    axum::serve(listener, app).await.unwrap();&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/db/connect.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/db/connect.rs" />
              <option name="originalContent" value="use anyhow::Result;&#10;use tokio_postgres::{Client, NoTls};&#10;&#10;use crate::config::Config;&#10;&#10;/// Obtain a connected `tokio_postgres::Client` and spawn the connection task.&#10;pub async fn get_client() -&gt; Result&lt;Client&gt; {&#10;    let cfg = Config::from_env();&#10;    let (client, connection) = tokio_postgres::connect(&amp;cfg.db_url, NoTls).await?;&#10;    // Drive the connection on a background task&#10;    tokio::spawn(async move {&#10;        if let Err(e) = connection.await {&#10;            eprintln!(&quot;connection error: {e}&quot;);&#10;        }&#10;    });&#10;    // Ensure AGE extension and graph exist&#10;    client&#10;        .batch_execute(&#10;            &quot;CREATE EXTENSION IF NOT EXISTS age;\nLOAD 'age';\nSET search_path = ag_catalog, \&quot;$user\&quot;, public;&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Create common vertex labels if they don't exist&#10;    let labels = vec![&quot;Node&quot;, &quot;TestNode&quot;, &quot;Person&quot;, &quot;City&quot;];&#10;    for label in labels {&#10;        let create_label_sql = format!(&#10;            &quot;SELECT ag_catalog.create_vlabel('sem_graph', '{}') WHERE NOT EXISTS (SELECT 1 FROM ag_catalog.ag_label WHERE name='{}' AND graph=17033);&quot;,&#10;            label, label&#10;        );&#10;        let _ = client.execute(&amp;create_label_sql, &amp;[]).await; // Ignore errors if label exists&#10;    }&#10;    // create graph if not exists&#10;    client&#10;        .batch_execute(&#10;            &quot;SELECT create_graph('sem_graph') WHERE NOT EXISTS (SELECT 1 FROM ag_graph WHERE name='sem_graph');&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Create embeddings table if it doesn't exist (explicitly in ag_catalog schema)&#10;    client&#10;        .batch_execute(&#10;            &quot;CREATE TABLE IF NOT EXISTS ag_catalog.embeddings (&#10;                 triplet_id BIGINT PRIMARY KEY,&#10;                 vec TEXT,&#10;                 lsh_bucket INTEGER,&#10;                 session_id TEXT,&#10;                 edge_text TEXT&#10;             );&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Create sessions metadata table (explicitly in ag_catalog schema)&#10;    client&#10;        .batch_execute(&#10;            &quot;CREATE TABLE IF NOT EXISTS ag_catalog.sessions (&#10;                 session_id TEXT PRIMARY KEY,&#10;                 ingested_at TIMESTAMP DEFAULT NOW(),&#10;                 node_count INTEGER,&#10;                 edge_count INTEGER&#10;             );&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Create edge evidence tracking table (explicitly in ag_catalog schema)&#10;    client&#10;        .batch_execute(&#10;            &quot;CREATE TABLE IF NOT EXISTS ag_catalog.edge_evidence (&#10;                 edge_id BIGINT,&#10;                 session_id TEXT,&#10;                 evidence_message_id TEXT,&#10;                 PRIMARY KEY (edge_id, evidence_message_id)&#10;             );&quot;&#10;        )&#10;        .await?;&#10;    &#10;    Ok(client)&#10;}&#10;" />
              <option name="updatedContent" value="use anyhow::Result;&#10;use tokio_postgres::{Client, NoTls};&#10;&#10;use crate::config::Config;&#10;&#10;/// Obtain a connected `tokio_postgres::Client` and spawn the connection task.&#10;pub async fn get_client() -&gt; Result&lt;Client&gt; {&#10;    let cfg = Config::from_env();&#10;    let (client, connection) = tokio_postgres::connect(&amp;cfg.db_url, NoTls).await?;&#10;    // Drive the connection on a background task&#10;    tokio::spawn(async move {&#10;        if let Err(e) = connection.await {&#10;            eprintln!(&quot;connection error: {e}&quot;);&#10;        }&#10;    });&#10;    &#10;    // Ensure pgvector extension exists (for message embeddings)&#10;    client&#10;        .batch_execute(&#10;            &quot;CREATE EXTENSION IF NOT EXISTS vector;&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Ensure AGE extension and graph exist&#10;    client&#10;        .batch_execute(&#10;            &quot;CREATE EXTENSION IF NOT EXISTS age;\nLOAD 'age';\nSET search_path = ag_catalog, \&quot;$user\&quot;, public;&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Create common vertex labels if they don't exist&#10;    let labels = vec![&quot;Node&quot;, &quot;TestNode&quot;, &quot;Person&quot;, &quot;City&quot;];&#10;    for label in labels {&#10;        let create_label_sql = format!(&#10;            &quot;SELECT ag_catalog.create_vlabel('sem_graph', '{}') WHERE NOT EXISTS (SELECT 1 FROM ag_catalog.ag_label WHERE name='{}' AND graph=17033);&quot;,&#10;            label, label&#10;        );&#10;        let _ = client.execute(&amp;create_label_sql, &amp;[]).await; // Ignore errors if label exists&#10;    }&#10;    // create graph if not exists&#10;    client&#10;        .batch_execute(&#10;            &quot;SELECT create_graph('sem_graph') WHERE NOT EXISTS (SELECT 1 FROM ag_graph WHERE name='sem_graph');&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Create embeddings table if it doesn't exist (explicitly in ag_catalog schema)&#10;    client&#10;        .batch_execute(&#10;            &quot;CREATE TABLE IF NOT EXISTS ag_catalog.embeddings (&#10;                 triplet_id BIGINT PRIMARY KEY,&#10;                 vec TEXT,&#10;                 lsh_bucket INTEGER,&#10;                 session_id TEXT,&#10;                 edge_text TEXT&#10;             );&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Create sessions metadata table (explicitly in ag_catalog schema)&#10;    client&#10;        .batch_execute(&#10;            &quot;CREATE TABLE IF NOT EXISTS ag_catalog.sessions (&#10;                 session_id TEXT PRIMARY KEY,&#10;                 ingested_at TIMESTAMP DEFAULT NOW(),&#10;                 node_count INTEGER,&#10;                 edge_count INTEGER&#10;             );&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Create edge evidence tracking table (explicitly in ag_catalog schema)&#10;    client&#10;        .batch_execute(&#10;            &quot;CREATE TABLE IF NOT EXISTS ag_catalog.edge_evidence (&#10;                 edge_id BIGINT,&#10;                 session_id TEXT,&#10;                 evidence_message_id TEXT,&#10;                 PRIMARY KEY (edge_id, evidence_message_id)&#10;             );&quot;&#10;        )&#10;        .await?;&#10;    &#10;    // Run message and knowledge graph schema migration&#10;    run_message_schema_migration(&amp;client).await?;&#10;    &#10;    Ok(client)&#10;}&#10;&#10;/// Run the message and knowledge graph schema migration&#10;async fn run_message_schema_migration(client: &amp;Client) -&gt; Result&lt;()&gt; {&#10;    println!(&quot;Running message schema migration...&quot;);&#10;    &#10;    // Enable UUID extension&#10;    client.execute(&quot;CREATE EXTENSION IF NOT EXISTS \&quot;uuid-ossp\&quot;;&quot;, &amp;[]).await?;&#10;    &#10;    // Conversations table&#10;    client.batch_execute(&#10;        &quot;CREATE TABLE IF NOT EXISTS conversations (&#10;            conversation_id UUID PRIMARY KEY,&#10;            created_at TIMESTAMP DEFAULT NOW(),&#10;            updated_at TIMESTAMP DEFAULT NOW(),&#10;            metadata JSONB DEFAULT '{}'::jsonb&#10;        );&quot;&#10;    ).await?;&#10;    &#10;    // Messages table&#10;    client.batch_execute(&#10;        &quot;CREATE TABLE IF NOT EXISTS messages (&#10;            message_id UUID PRIMARY KEY,&#10;            conversation_id UUID NOT NULL REFERENCES conversations(conversation_id) ON DELETE CASCADE,&#10;            content TEXT NOT NULL,&#10;            created_at TIMESTAMP DEFAULT NOW(),&#10;            metadata JSONB DEFAULT '{}'::jsonb&#10;        );&quot;&#10;    ).await?;&#10;    &#10;    // Message embeddings with pgvector&#10;    client.batch_execute(&#10;        &quot;CREATE TABLE IF NOT EXISTS message_embeddings (&#10;            message_id UUID PRIMARY KEY REFERENCES messages(message_id) ON DELETE CASCADE,&#10;            embedding vector(768) NOT NULL,&#10;            embedding_model VARCHAR(100) DEFAULT 'nomic-embed-text-v1.5',&#10;            created_at TIMESTAMP DEFAULT NOW()&#10;        );&quot;&#10;    ).await?;&#10;    &#10;    // Knowledge graph nodes&#10;    client.batch_execute(&#10;        &quot;CREATE TABLE IF NOT EXISTS kg_nodes (&#10;            node_id VARCHAR(255),&#10;            conversation_id UUID REFERENCES conversations(conversation_id) ON DELETE CASCADE,&#10;            node_type VARCHAR(100),&#10;            created_at TIMESTAMP DEFAULT NOW(),&#10;            PRIMARY KEY (node_id, conversation_id)&#10;        );&quot;&#10;    ).await?;&#10;    &#10;    // Knowledge graph edges&#10;    client.batch_execute(&#10;        &quot;CREATE TABLE IF NOT EXISTS kg_edges (&#10;            edge_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),&#10;            conversation_id UUID REFERENCES conversations(conversation_id) ON DELETE CASCADE,&#10;            source_node VARCHAR(255) NOT NULL,&#10;            target_node VARCHAR(255) NOT NULL,&#10;            relation VARCHAR(255) NOT NULL,&#10;            evidence_message_ids UUID[] NOT NULL,&#10;            created_at TIMESTAMP DEFAULT NOW()&#10;        );&quot;&#10;    ).await?;&#10;    &#10;    // Create indexes&#10;    client.batch_execute(&#10;        &quot;CREATE INDEX IF NOT EXISTS idx_messages_conversation ON messages(conversation_id);&#10;         CREATE INDEX IF NOT EXISTS idx_message_embeddings_ivfflat ON message_embeddings &#10;             USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);&#10;         CREATE INDEX IF NOT EXISTS idx_kg_edges_conversation ON kg_edges(conversation_id);&#10;         CREATE INDEX IF NOT EXISTS idx_kg_edges_evidence ON kg_edges USING GIN(evidence_message_ids);&#10;         CREATE INDEX IF NOT EXISTS idx_kg_nodes_conversation ON kg_nodes(conversation_id);&#10;         CREATE INDEX IF NOT EXISTS idx_kg_nodes_type ON kg_nodes(node_type);&quot;&#10;    ).await?;&#10;    &#10;    println!(&quot;Message schema migration completed successfully&quot;);&#10;    Ok(())&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/db/kg_ops.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/db/kg_ops.rs" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="use tokio_postgres::{Client, Error};&#10;use uuid::Uuid;&#10;use crate::db::models::*;&#10;use crate::db::message_ops::insert_conversation;&#10;&#10;/// Insert a knowledge graph node&#10;pub async fn insert_kg_node(&#10;    client: &amp;Client,&#10;    conversation_id: Uuid,&#10;    node: &amp;KGNode,&#10;) -&gt; Result&lt;(), Error&gt; {&#10;    client.execute(&#10;        &quot;INSERT INTO kg_nodes (node_id, conversation_id, node_type)&#10;         VALUES ($1, $2, $3)&#10;         ON CONFLICT (node_id, conversation_id) DO UPDATE&#10;         SET node_type = EXCLUDED.node_type&quot;,&#10;        &amp;[&amp;node.id, &amp;conversation_id, &amp;node.node_type],&#10;    ).await?;&#10;    Ok(())&#10;}&#10;&#10;/// Insert a knowledge graph edge with evidence&#10;pub async fn insert_kg_edge(&#10;    client: &amp;Client,&#10;    conversation_id: Uuid,&#10;    edge: &amp;KGEdge,&#10;) -&gt; Result&lt;(), Error&gt; {&#10;    client.execute(&#10;        &quot;INSERT INTO kg_edges (conversation_id, source_node, target_node, relation, evidence_message_ids)&#10;         VALUES ($1, $2, $3, $4, $5)&quot;,&#10;        &amp;[&#10;            &amp;conversation_id,&#10;            &amp;edge.source,&#10;            &amp;edge.target,&#10;            &amp;edge.relation,&#10;            &amp;edge.evidence_message_ids,&#10;        ],&#10;    ).await?;&#10;    Ok(())&#10;}&#10;&#10;/// Batch insert knowledge graph data for multiple conversations&#10;pub async fn batch_insert_knowledge_graph(&#10;    client: &amp;Client,&#10;    kg_data: ConversationKnowledgeGraph,&#10;) -&gt; Result&lt;(usize, usize, Vec&lt;String&gt;), Error&gt; {&#10;    let mut total_nodes = 0;&#10;    let mut total_edges = 0;&#10;    let mut errors = Vec::new();&#10;&#10;    for (conversation_id, kg) in kg_data.conversations {&#10;        // Ensure conversation exists&#10;        if let Err(e) = insert_conversation(client, conversation_id).await {&#10;            errors.push(format!(&quot;Conversation {}: {}&quot;, conversation_id, e));&#10;            continue;&#10;        }&#10;&#10;        // Insert nodes&#10;        for node in &amp;kg.nodes {&#10;            match insert_kg_node(client, conversation_id, node).await {&#10;                Ok(_) =&gt; total_nodes += 1,&#10;                Err(e) =&gt; {&#10;                    errors.push(format!(&quot;Node {} in conv {}: {}&quot;, node.id, conversation_id, e));&#10;                    eprintln!(&quot;Failed to insert node {} in conversation {}: {}&quot;, &#10;                        node.id, conversation_id, e);&#10;                }&#10;            }&#10;        }&#10;&#10;        // Insert edges&#10;        for edge in &amp;kg.edges {&#10;            match insert_kg_edge(client, conversation_id, edge).await {&#10;                Ok(_) =&gt; total_edges += 1,&#10;                Err(e) =&gt; {&#10;                    errors.push(format!(&quot;Edge {}-&gt;{} in conv {}: {}&quot;, &#10;                        edge.source, edge.target, conversation_id, e));&#10;                    eprintln!(&quot;Failed to insert edge {}-&gt;{} in conversation {}: {}&quot;, &#10;                        edge.source, edge.target, conversation_id, e);&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    Ok((total_nodes, total_edges, errors))&#10;}&#10;&#10;/// Query knowledge graph edges by keyword matching&#10;pub async fn get_edges_by_query(&#10;    client: &amp;Client,&#10;    query_keywords: &amp;[String],&#10;    limit: i64,&#10;) -&gt; Result&lt;Vec&lt;KGEdgeWithContext&gt;, Error&gt; {&#10;    if query_keywords.is_empty() {&#10;        return Ok(Vec::new());&#10;    }&#10;&#10;    // Convert keywords to ILIKE patterns&#10;    let patterns: Vec&lt;String&gt; = query_keywords.iter()&#10;        .map(|kw| format!(&quot;%{}%&quot;, kw))&#10;        .collect();&#10;&#10;    let rows = client.query(&#10;        &quot;SELECT DISTINCT conversation_id, source_node, target_node, relation, evidence_message_ids&#10;         FROM kg_edges&#10;         WHERE source_node ILIKE ANY($1) &#10;            OR target_node ILIKE ANY($1)&#10;            OR relation ILIKE ANY($1)&#10;         LIMIT $2&quot;,&#10;        &amp;[&amp;patterns, &amp;limit],&#10;    ).await?;&#10;&#10;    let edges = rows.iter().map(|row| KGEdgeWithContext {&#10;        conversation_id: row.get(0),&#10;        source: row.get(1),&#10;        target: row.get(2),&#10;        relation: row.get(3),&#10;        evidence_message_ids: row.get(4),&#10;    }).collect();&#10;&#10;    Ok(edges)&#10;}&#10;&#10;/// Get all edges that contain any of the specified message IDs in their evidence&#10;pub async fn get_edges_by_message_ids(&#10;    client: &amp;Client,&#10;    message_ids: &amp;[Uuid],&#10;) -&gt; Result&lt;Vec&lt;KGEdgeWithContext&gt;, Error&gt; {&#10;    if message_ids.is_empty() {&#10;        return Ok(Vec::new());&#10;    }&#10;&#10;    let rows = client.query(&#10;        &quot;SELECT conversation_id, source_node, target_node, relation, evidence_message_ids&#10;         FROM kg_edges&#10;         WHERE evidence_message_ids &amp;&amp; $1::uuid[]&quot;,&#10;        &amp;[&amp;message_ids],&#10;    ).await?;&#10;&#10;    let edges = rows.iter().map(|row| KGEdgeWithContext {&#10;        conversation_id: row.get(0),&#10;        source: row.get(1),&#10;        target: row.get(2),&#10;        relation: row.get(3),&#10;        evidence_message_ids: row.get(4),&#10;    }).collect();&#10;&#10;    Ok(edges)&#10;}&#10;&#10;/// Get statistics about the knowledge graph&#10;pub async fn get_kg_statistics(client: &amp;Client) -&gt; Result&lt;serde_json::Value, Error&gt; {&#10;    let node_count: i64 = client.query_one(&#10;        &quot;SELECT COUNT(*) FROM kg_nodes&quot;,&#10;        &amp;[]&#10;    ).await?.get(0);&#10;&#10;    let edge_count: i64 = client.query_one(&#10;        &quot;SELECT COUNT(*) FROM kg_edges&quot;,&#10;        &amp;[]&#10;    ).await?.get(0);&#10;&#10;    let conversation_count: i64 = client.query_one(&#10;        &quot;SELECT COUNT(DISTINCT conversation_id) FROM conversations&quot;,&#10;        &amp;[]&#10;    ).await?.get(0);&#10;&#10;    let message_count: i64 = client.query_one(&#10;        &quot;SELECT COUNT(*) FROM messages&quot;,&#10;        &amp;[]&#10;    ).await?.get(0);&#10;&#10;    Ok(serde_json::json!({&#10;        &quot;total_nodes&quot;: node_count,&#10;        &quot;total_edges&quot;: edge_count,&#10;        &quot;total_conversations&quot;: conversation_count,&#10;        &quot;total_messages&quot;: message_count,&#10;    }))&#10;}&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/db/mod.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/db/mod.rs" />
              <option name="originalContent" value="pub mod connect;&#10;pub mod graph;&#10;pub mod vector;&#10;" />
              <option name="updatedContent" value="pub mod connect;&#10;pub mod graph;&#10;pub mod vector;&#10;pub mod models;&#10;pub mod message_ops;&#10;pub mod kg_ops;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/db/models.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/db/models.rs" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="use serde::{Deserialize, Serialize};&#10;use uuid::Uuid;&#10;use std::collections::HashMap;&#10;&#10;// ============================================================================&#10;// Turn Embeddings Models (from turn_embeddings.json)&#10;// ============================================================================&#10;&#10;#[derive(Debug, Deserialize, Serialize, Clone)]&#10;pub struct TurnEmbedding {&#10;    pub message_id: Uuid,&#10;    pub conversation_id: Uuid,&#10;    pub actual_text: String,&#10;    pub embedding: Vec&lt;f32&gt;, // 768-dim Nomic embeddings&#10;}&#10;&#10;// ============================================================================&#10;// Knowledge Graph Models (from enhanced_pipeline_full_results.json)&#10;// ============================================================================&#10;&#10;#[derive(Debug, Deserialize, Serialize)]&#10;pub struct ConversationKnowledgeGraph {&#10;    #[serde(flatten)]&#10;    pub conversations: HashMap&lt;Uuid, KnowledgeGraphData&gt;,&#10;}&#10;&#10;#[derive(Debug, Deserialize, Serialize, Clone)]&#10;pub struct KnowledgeGraphData {&#10;    pub nodes: Vec&lt;KGNode&gt;,&#10;    pub edges: Vec&lt;KGEdge&gt;,&#10;    #[serde(skip_serializing_if = &quot;Option::is_none&quot;)]&#10;    pub pipeline_metadata: Option&lt;serde_json::Value&gt;,&#10;}&#10;&#10;#[derive(Debug, Deserialize, Serialize, Clone)]&#10;pub struct KGNode {&#10;    pub id: String,&#10;    #[serde(rename = &quot;type&quot;)]&#10;    pub node_type: String,&#10;}&#10;&#10;#[derive(Debug, Deserialize, Serialize, Clone)]&#10;pub struct KGEdge {&#10;    pub source: String,&#10;    pub target: String,&#10;    pub relation: String,&#10;    pub evidence_message_ids: Vec&lt;Uuid&gt;,&#10;}&#10;&#10;// ============================================================================&#10;// Database Entity Models&#10;// ============================================================================&#10;&#10;#[derive(Debug, Serialize, Clone)]&#10;pub struct Conversation {&#10;    pub conversation_id: Uuid,&#10;}&#10;&#10;#[derive(Debug, Serialize, Clone)]&#10;pub struct Message {&#10;    pub message_id: Uuid,&#10;    pub conversation_id: Uuid,&#10;    pub content: String,&#10;}&#10;&#10;#[derive(Debug, Serialize, Clone)]&#10;pub struct MessageWithRelevance {&#10;    pub message_id: Uuid,&#10;    pub conversation_id: Uuid,&#10;    pub content: String,&#10;    pub relevance_score: f32,&#10;}&#10;&#10;// ============================================================================&#10;// LLM Context Models&#10;// ============================================================================&#10;&#10;#[derive(Debug, Serialize)]&#10;pub struct LLMContextMessage {&#10;    pub role: String,&#10;    pub content: String,&#10;    pub message_id: Uuid,&#10;    pub relevance_score: f32,&#10;}&#10;&#10;#[derive(Debug, Serialize)]&#10;pub struct FormattedLLMContext {&#10;    pub messages: Vec&lt;LLMContextMessage&gt;,&#10;    pub total_tokens_estimate: usize,&#10;    pub context_window_used: f32, // percentage&#10;    pub unique_conversations: usize,&#10;}&#10;&#10;// ============================================================================&#10;// API Response Models&#10;// ============================================================================&#10;&#10;#[derive(Debug, Serialize)]&#10;pub struct IngestResponse {&#10;    pub success: bool,&#10;    pub total_processed: usize,&#10;    pub total_inserted: usize,&#10;    pub duration_ms: u128,&#10;    pub errors: Vec&lt;String&gt;,&#10;}&#10;&#10;#[derive(Debug, Serialize)]&#10;pub struct KGEdgeWithContext {&#10;    pub source: String,&#10;    pub target: String,&#10;    pub relation: String,&#10;    pub evidence_message_ids: Vec&lt;Uuid&gt;,&#10;    pub conversation_id: Uuid,&#10;}&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>